---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "figures/README-",
  out.width = "100%"
)
```

## DeepG4ToolsComparison: A snakemake pipeline to run and compare G4 DNA prediction tools with DeepG4


The code to generate the precision/recall curve is available [here](prediction_genome).

### Overview


It's based on [Snakemake](https://snakemake.readthedocs.io/en/stable/) to manage the workflow and [Docker](https://www.docker.com/) to isolate the application and run it with the appropriate tool versions.


### Installation

#### Clone the repository :

```bash
git clone https://github.com/morphos30/DeepG4ToolsComparison.git
cd DeepG4ToolsComparison
```
#### Install the docker image and run it :

```bash
docker build . -t morphos30/g4docker -f Dockerfile/Dockerfile
docker run -it -v $(pwd):/DeepG4ToolsComparison morphos30/g4docker /bin/bash
```

Where `$(pwd)` is the working directory of `DeepG4ToolsComparison` on your computer.


#### Launch the pipeline :

```bash
cd /DeepG4ToolsComparison
snakemake --use-conda -j 30
```

You have to set the option `--use-conda` in order to install and run each tool in its proper environment.

### Workflow specifications

#### Input

* DNA sequences into bed format, split into positive set and negative set, written into the bed directory.

__Note :__ if you want add a new dataset, edit the `Snakefile` file and add the bed files in the dictionnary `EXPERIMENTS`, without the `.bed` extension. Example :

`TestSet_Peaks_BG4_G4seq_HaCaT_GSE76688_hg19_201b_Ctrl_gkmSVM_0.8_42_Ctrl_gkmSVM.bed`
`TestSet_Peaks_BG4_G4seq_HaCaT_GSE76688_hg19_201b_Ctrl_gkmSVM_0.8_42.bed`

```python
EXPERIMENTS = {
  "TestSet_Peaks_BG4_G4seq_HaCaT_GSE76688_hg19_201b_Ctrl_gkmSVM_0.8_42_Ctrl_gkmSVM":{"CTRL":"TestSet_Peaks_BG4_G4seq_HaCaT_GSE76688_hg19_201b_Ctrl_gkmSVM_0.8_42_Ctrl_gkmSVM","EXP":"TestSet_Peaks_BG4_G4seq_HaCaT_GSE76688_hg19_201b_Ctrl_gkmSVM_0.8_42"}
}
```

Where `CTRL` is the negative set and `EXP` is the positive set.

* DNA Accessibility (ATAC-seq/DNAse-seq/MNase-seq) in bigwig format or directly the averaged value for each sequence in a `one-column tsv` file.

```python
ATACFILE = {
	"TestSet_Peaks_BG4_G4seq_HaCaT_GSE76688_hg19_201b_Ctrl_gkmSVM":["ATAC_entinostat_mean.bw"]
}
```

or `one-column tsv` file in `fasta/{Experiment_name}/{Experiment_name}_atac_merged.tsv`. Example :

`fasta/TestSet_Peaks_BG4_G4seq_HaCaT_GSE76688_hg19_201b_Ctrl_gkmSVM/TestSet_Peaks_BG4_G4seq_HaCaT_GSE76688_hg19_201b_Ctrl_gkmSVM_atac_merged.tsv`

```
head TestSet_Peaks_BG4_G4seq_HaCaT_GSE76688_hg19_201b_Ctrl_gkmSVM_atac_merged.tsv 
0.01628741641898675
0.028752257447422012
0.028878783223623482
0.055516399884055316
0.02825982069785745
0.03582923041809851
0.023904436394151577
0.07724288611280039
0.01740800116454673
0.05779605688479145
```

#### Rulegraph :

```{r, echo=FALSE, out.width="150%", fig.cap=""}
knitr::include_graphics("rulegraph.svg")
```

#### Workflow output for each tools :

```{r define, echo=F, message=FALSE, warning=FALSE}
require(tidyverse)
require(kableExtra)
datatools <- tibble(
  "Outputs" = c(
    "ATACDeepG4_ATACnormBG",
"ATACDeepG4_classictuningOH5",
"penguinn_retrained",
"penguinn",
"G4detector_retrained",
"G4detector",
"quadron_retrained",
"quadron_score"),
"Tools" = str_remove(str_extract(Outputs,".+_|.+"),"_"),
"Methods"=c(
      "DeepG4 using accessibily (DeepG4 in paper)",
"DeepG4 without accessibility (DeepG4* in paper)",
            "penguinn using custom model trained on __BG4G4seq__ dataset",
            "penguinn using default model",
            "G4detector using custom model trained on __BG4G4seq__ dataset",
            "G4detector using default model",
            "quadron using custom model trained on __BG4G4seq__ dataset",
            "quadron using default model"
            )
)
# datatools <- tibble(
#   "Outputs" = c(
#     "ATACDeepG4_ATACnormBG",
# "ATACDeepG4_classictuningOH5",
# "penguinn_retrained",
# "penguinn",
# "G4detector_retrained",
# "G4detector",
# "quadron_retrained",
# "quadron_score",
# 
# "G4CatchAll_max",
# "G4CatchAll_mean",
# "G4CatchAll_sum",
# 
# "G4hunter_max",
# "G4hunter_mean",
# "G4hunter_sum",
# "G4hunterRF",
# 
# 
# "qparse_max",
# "qparse_mean",
# "qparse_sum",
# "quadparser_max",
# "quadparser_mean",
# "quadparser_sum",
# "gqrs_mapper_max",
# "gqrs_mapper_mean",
# "gqrs_mapper_sum",
# 
# "pqsfinder"),
# "Tools" = str_remove(str_extract(Outputs,".+_|.+"),"_"),
# "Methods"=c(
#       "DeepG4 using accessibily (DeepG4 in paper)",
# "DeepG4 without accessibility (DeepG4* in paper)",
#             "penguinn using custom model trained on __BG4G4seq__ dataset",
#             "penguinn using default model",
#             "G4detector using custom model trained on __BG4G4seq__ dataset",
#             "G4detector using default model",
#             "quadron using custom model trained on __BG4G4seq__ dataset",
#             "quadron using default model",
#             
#             "G4CatchAll max score is calculated on each sequence",
#             "G4CatchAll mean score is calculated on each sequence",
#             "G4CatchAll sum score is calculated on each sequence",
#             
#             "G4hunter max score is calculated on each sequence",
#             "G4hunter mean score is calculated on each sequence",
#             "G4hunter sum score is calculated on each sequence",
#             
#             "G4Hunter implemented within a Random Forest",
#             
#             "qparse max score is calculated on each sequence",
#             "qparse mean score is calculated on each sequence",
#             "qparse sum score is calculated on each sequence",
#             "quadparser max score is calculated on each sequence",
#             "quadparser mean score is calculated on each sequence",
#             "quadparser sum score is calculated on each sequence",
#             "gqrs_mapper max score is calculated on each sequence",
#             "gqrs_mapper mean score is calculated on each sequence",
#             "gqrs_mapper sum score is calculated on each sequence",
#             "default pqsfinder score calculated on each sequence"
#             )
# )
```

```{r show1,echo=F}
datatools %>% kable(caption = "",format="markdown",escape=F) 
```


### Main result

```{r boxplot1, echo=TRUE, fig.height=8, fig.width=10,dev="png",dpi=150,echo=F,warning=F,message=F}
require(ggplot2)
#peaks BG4G4seq

theme_set(theme_classic(base_size=18))
theme_update(legend.text=element_text(size=12),
             legend.direction = "vertical",
             # legend.box = "horizontal",
             # legend.position = c(1,0.025),
             legend.position = "bottom",
             axis.title.y = element_blank(),
             axis.ticks.x = element_blank(),
             axis.text.x = element_blank(),
             legend.justification = c(0, 0),
             axis.text.y = element_text(color = "black",size=16))
fres <- read_tsv("results/recap_AUC_4.tsv")
cc <- fres %>% 
  filter(metric == "AUC") %>% dplyr::select(-metric) %>% dplyr::rename(AUC="value") %>% 
  filter(Tool %in% c("ATACDeepG4_ATACnormBG","ATACDeepG4_classictuningOH5","G4detector_tsv","penguinn","quadron_score")) %>%
  filter(TypeExp %in% c("Peaks_G4P_G4seq","TestSet_Peaks_BG4_G4seq","Peaks_BG4_G4seq","Peaks_qG4","TestSet_Peaks_G4seqpm_BG4")) %>%
  # unite(Files,TypeExp,Exp,cell_line,Ctrl) %>%
  unite(Files,Exp,cell_line) %>%
  group_by(Files) %>%
  arrange(desc(AUC)) %>% mutate(Classement = 1:dplyr::n()) %>%
  ungroup() %>%
  mutate(Tool = str_replace(Tool,"ATACDeepG4_classictuningOH5","DeepG4*")) %>% 
  mutate(Tool = str_replace(Tool,"ATACDeepG4_ATACnormBG","DeepG4")) %>% 
  mutate(my_text = ifelse(Tool %in% c("DeepG4*","DeepG4"),str_c(Classement,"\n(",round(AUC,2),")"),
                          str_c(Classement,"\n(",round(AUC,1),")"))) %>% 
  mutate(Tool = str_remove_all(Tool,"^ATAC|_ATACtuningOH5|_sum|_mean|_tsv|_max|_score")) %>% 
  mutate(Tool = str_to_title(Tool)) %>% 
  mutate(Tool = str_replace(Tool,"_"," ")) %>% 
  mutate(Tool = str_replace(Tool,"g4","G4")) %>% 
  mutate(Tool = fct_reorder(Tool,AUC,mean)) 
cctext <- cc %>% group_by(Tool) %>% summarise(meanscore = mean(AUC),AUC = sum(AUC))

cc <- cc %>% 
  separate(Files,into = c("GSE","Exp")) %>% 
  mutate(Files = case_when(
    GSE == "GSE76688" & Exp == "HaCaT" ~ glue::glue("{Exp} (Testing set, {GSE})"),
    GSE == "GSE99205" & Exp == "HaCaT" ~ glue::glue("{Exp} (Independent experiment, {GSE})"),
    TRUE ~ glue::glue("{Exp} ({GSE})")
  )) %>% dplyr::select(-GSE,-Exp) %>% 
  mutate(Files =factor(Files,levels = rev(c("HaCaT (Testing set, GSE76688)","HaCaT (Independent experiment, GSE99205)","K562 (GSE107690)","HEKnp (GSE76688)","293T (GSE133379)","A549 (GSE133379)","H1975 (GSE133379)","HeLaS3 (GSE133379)")))) %>% 
  mutate(col_Files = fct_recode(Files,`#2c3e50`="HaCaT (Testing set, GSE76688)",`#2980b9`="HaCaT (Independent experiment, GSE99205)",`#8e44ad`="K562 (GSE107690)",`#27ae60`="HEKnp (GSE76688)",`#c0392b`="293T (GSE133379)",`#d35400`="A549 (GSE133379)",`#16a085`="H1975 (GSE133379)",`#60a3bc`="HeLaS3 (GSE133379)"))
  
cc%>%
  ggplot(aes(x=fct_reorder(Tool,AUC,mean),y=AUC,fill=Files)) +
  geom_bar(alpha=0.3,stat="identity",col="black") +
  scale_y_continuous(expand=c(0,0),limits = c(0,9)) +
  coord_flip(clip="off") +
  geom_text(aes(label=my_text), position=position_stack(0.45), size=4,lineheight = .8) +
  ylab("Ranking (AUROC) on 9 datasets\n(Rectangle width is proportional to AUROC)") + xlab("Tools") +
  geom_label(data=cctext,aes(x=Tool,y=AUC,label = round(meanscore,3)),fill="white",position = position_dodge(width = 1),hjust = -0.1,size=5) +
  scale_fill_manual("Dataset",values = levels(cc$col_Files)) -> p3
print(p3)


```
